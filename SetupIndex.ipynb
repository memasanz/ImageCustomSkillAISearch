{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search with Azure AI Vision multimodal embeddings for text-to-image queries\n",
    "\n",
    "As a scenario, this code shows you an approach for text-to-image vector queries. As a technical sample, it demonstrates how to call a custom embedding model for situations where you want models other an Azure OpenAI or OpenAI for vectorization. The multimodal embeddings used in this sample are provided by [Azure AI Vision 4.0](https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval) and the [Image Retrieval REST API](https://learn.microsoft.com/rest/api/computervision/image-retrieval) which supports built-in vectorization of images. \n",
    "\n",
    "For indexing, the pattern uses a custom skill to wrap an Azure function app used to call the Image Retrieval API. Provisioning of this function app and custom skill is fully automated and included as a step in this notebook.\n",
    "\n",
    "The function app is also used during queries, as the vectorizer. A vectorizer specifies which embedding model to use for vectorizing a text query string. As always, it's strongly recommended that query vectorization is performed using the same embedding model used for document vectorization during indexing.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "+ [Azure AI Search](https://learn.microsoft.com/azure/search/search-create-service-portal), any region and tier, but we recommend Basic or higher for this workload.\n",
    "\n",
    "+ [Azure Blob storage](https://learn.microsoft.com/azure/storage/common/storage-account-create), used as the data source during indexing.\n",
    "\n",
    "+ [azd](https://learn.microsoft.com/azure/developer/azure-developer-cli/install-azd), used to deploy an Azure function app and Azure AI Vision in your Azure subscription.\n",
    "\n",
    "We use the [Azure Python SDK](https://learn.microsoft.com/en-us/python/api/azure-search-documents/?view=azure-python-preview) for indexer-driven indexing and vector query operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r azure-search-vector-image-python-sample-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv() # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "blob_connection_string = os.environ[\"BLOB_CONNECTION_STRING\"]\n",
    "blob_container_name = os.environ[\"BLOB_CONTAINER_NAME\"]\n",
    "function_app_url = os.environ[\"function_app_url\"]\n",
    "sas_token = os.environ[\"SAS_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import SearchIndexerDataContainer, SearchIndexerDataSourceConnection\n",
    "# Create a data source \n",
    "ds_client = SearchIndexerClient(endpoint, credential)\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create skillset\n",
    "from azure.search.documents.indexes.models import (\n",
    "    WebApiSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchIndexerSkillset\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  \n",
    "  \n",
    "skill = WebApiSkill(  \n",
    "    description=\"Skill to generate image embeddings via a custom endpoint\",  \n",
    "    context=\"/document\",\n",
    "    http_method=\"POST\",\n",
    "    batch_size=10, # Controls how many images are sent to the custom skill at a time\n",
    "    uri=function_app_url,\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"imageUrl\", source=\"/document/metadata_storage_path\"),\n",
    "        InputFieldMappingEntry(name=\"sasToken\", source=\"/document/metadata_storage_sas_token\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"vector\", target_name=\"vector\")\n",
    "    ],\n",
    ")\n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to extract image vector\",  \n",
    "    skills=[skill],  \n",
    ")\n",
    "  \n",
    "ds_client.create_or_update_skillset(skillset)  \n",
    "print(f'Skillset {skillset.name} created')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create index\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex,\n",
    "    CustomVectorizer,\n",
    "    CustomWebApiParameters\n",
    ")\n",
    "\n",
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  \n",
    "fields = [  \n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),  \n",
    "    SearchField(name=\"imageUrl\", type=SearchFieldDataType.String),  \n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
    "    SearchField(  \n",
    "        name=\"imageVector\",  \n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "        vector_search_dimensions=1024,  \n",
    "        vector_search_profile_name=\"myHnswProfile\",  \n",
    "    ),  \n",
    "]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],  \n",
    "   profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\", \n",
    "            vectorizer=\"customVectorizer\"\n",
    "        )\n",
    "    ],\n",
    "    vectorizers=[  \n",
    "        CustomVectorizer(name=\"customVectorizer\", custom_web_api_parameters=CustomWebApiParameters(uri=function_app_url))\n",
    "    ]\n",
    ")\n",
    "  \n",
    "# Create the search index with the vector search configuration  \n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create indexer\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to process images\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,  \n",
    "    field_mappings=[  \n",
    "        FieldMapping(source_field_name=\"metadata_storage_path\", target_field_name=\"imageUrl\"),  \n",
    "        FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")  \n",
    "    ],  \n",
    "    output_field_mappings=[  \n",
    "        FieldMapping(source_field_name=\"/document/vector\", target_field_name=\"imageVector\")  \n",
    "    ]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f'{indexer_name} is created and running. It will be several minutes before you can run the queries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import (\n",
    "    VectorizableTextQuery\n",
    ")\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "query = \"red apple\"  \n",
    "  \n",
    "# Initialize the SearchClient  \n",
    "search_client = SearchClient(endpoint, index_name, credential)  \n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"imageVector\")  \n",
    "\n",
    "# Perform vector search  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"imageUrl\"],\n",
    "    top=1\n",
    ")   \n",
    "  \n",
    "# Print the search results  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Image URL: {result['imageUrl']}\") \n",
    "    display(Image(url=result['imageUrl'] + \"?\" + sas_token)) \n",
    "    print(\"\\n\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
